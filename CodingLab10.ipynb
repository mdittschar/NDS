{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Neural Data Science_\n",
    "\n",
    "Lecturer: Prof. Dr. Philipp Berens\n",
    "\n",
    "Tutors: Jonas Beck, Ziwei Huang, Rita González Márquez\n",
    "\n",
    "Summer term 2022\n",
    "\n",
    "Names: FILL IN YOUR NAMES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Lab 10 \n",
    "\n",
    "Introduction into the analysis of neural morphologies (10 pts + bonus 3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The anatomical shape of a neuron — its morphology — has fascinated scientists ever since the pioneering work of Cajal (Ramon y Cajal, 1911). A neuron's dendritic and axonal processes naturally decide what other neurons it can connect to, hence, its shape plays an important role for its function in the circuit. In particular, different functional types of neurons have fundamentally different morphologies.\n",
    "\n",
    "This notebook will introduce you to the analysis of neural morphologies using the dendrites of over $500$ retinal ganglion cells. The aim is to teach you two different ways of representing morphologies and give you an impression of their repsective strengths and weaknesses.\n",
    "\n",
    "### 1. Data\n",
    "\n",
    "The data set contains morphological reconstructions of $599$ retinal ganglion cell dendrites with cell type label and projection target to either the parabigeminal (Pbg) or the pulvinar nucleus (LP)([Reinhard et al. (2019)](https://elifesciences.org/articles/50697)). \n",
    "Here we only keep cells that map to clusters with more than six cells per cluster which leads to $550$ remaining reconstructions. \n",
    "\n",
    "Download the data file `nda_ex_10_data.zip` from ILIAS and unzip it in a subfolder `../data/`\n",
    "\n",
    "\n",
    "### Software\n",
    "\n",
    "We will use MorphoPy (Laturnus, et al., 2020; https://github.com/berenslab/MorphoPy) for this exercise. We recommend to use the Github version, as it is more up-to-date:\n",
    "\n",
    "```\n",
    "git clone https://github.com/berenslab/MorphoPy\n",
    "pip install -e MorphoPy\n",
    "```\n",
    "\n",
    "Most of the computations and even some plottings will be handled by MorphoPy. You can learn more about MorphoPy's APIs in this [tutorial](https://nbviewer.jupyter.org/github/berenslab/MorphoPy/blob/master/notebooks/MORPHOPY%20Tutorial.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from morphopy.computation import file_manager\n",
    "from morphopy.neurontree.plotting import show_threeview\n",
    "from morphopy.neurontree import NeuronTree as nt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_context('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File format\n",
    "\n",
    "Morphological reconstructions are typically stored in the SWC file format, a simple text file that holds node information in each row and connects nodes through the `parent` node id. A parent id of -1 indicates no parent, so the starting point of the tree graph, also called the root. \n",
    "The `type` label indicates the node type (1: somatic , 2: axonal, 3: dendritic (basal), 4: dendritic (apical), 5+: custom).\n",
    "The code snippet below loads in one swc file and prints its head. \n",
    "\n",
    "You can find a more detailed specification of SWC and SWC+ [here](http://www.neuronland.org/NLMorphologyConverter/MorphologyFormats/SWC/Spec.html) and [here](https://neuroinformatics.nl/swcPlus/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_swc(filepath):\n",
    "    \"\"\" \n",
    "    Loads in the swc located at filepath as a pandas dataframe.\n",
    "    \"\"\"\n",
    "    swc = pd.read_csv(filepath, delim_whitespace=True, comment='#',\n",
    "                      names=['n', 'type', 'x', 'y', 'z', 'radius', 'parent'], index_col=False)\n",
    "    return swc\n",
    "\n",
    "colors = sns.color_palette('rainbow_r', n_colors=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>radius</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n  type     x     y     z  radius  parent\n",
       "0  1     1   0.0   0.0  47.0     1.0      -1\n",
       "1  2     3  -3.0   0.0  47.0     1.0       1\n",
       "2  3     3  17.0  -8.0  51.0     1.0       1\n",
       "3  4     3  24.0 -31.0  38.0     1.0       3\n",
       "4  5     3   2.0  14.0  42.0     1.0       1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../data/nda_ex_10_data/'\n",
    "data_path = PATH + 'neurons/soma-centered/'\n",
    "filename = '0006_00535_4L_C02_01.swc'\n",
    "filepath = data_path + filename\n",
    "\n",
    "swc = load_swc(filepath)\n",
    "swc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels `x`, `y`, and `z` hold a node's 3D coordinate in tracing space (here in microns). For reasons of simplicity we will work with reconstructions that are soma centered in XY.\n",
    "\n",
    "The assigned cell type labels are stored in the file `rgc_labels.csv` and indexed by their `Cell_nr`. In this file you find three different cluster assignments: `clusterA` is the assignment of the authors (clus1 -- clus14), `clusterB` is the respective cluster identifier of the [Eyewire museum](http://museum.eyewire.org) (also see [Bae et al. 2018](https://www.sciencedirect.com/science/article/pii/S0092867418305725)), and `clusterC` are molecular or functional label names when available. \n",
    "We have formatted the cluster assignments of the authors (`clusterA`) into integer values and stored them in the column `cluster`, which we will use in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell_nr</th>\n",
       "      <th>projection_site</th>\n",
       "      <th>clusterA</th>\n",
       "      <th>clusterB</th>\n",
       "      <th>clusterC</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LP</td>\n",
       "      <td>clus6</td>\n",
       "      <td>4ow</td>\n",
       "      <td>tOFFα</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>LP</td>\n",
       "      <td>clus2</td>\n",
       "      <td>2an</td>\n",
       "      <td>F-mini-OFF</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>LP</td>\n",
       "      <td>clus1</td>\n",
       "      <td>1wt</td>\n",
       "      <td>sOFFα</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>LP</td>\n",
       "      <td>clus7</td>\n",
       "      <td>5to</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>LP</td>\n",
       "      <td>clus10</td>\n",
       "      <td>6sn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cell_nr projection_site clusterA clusterB    clusterC  cluster\n",
       "1        2              LP    clus6      4ow       tOFFα        6\n",
       "2        3              LP    clus2      2an  F-mini-OFF        2\n",
       "3        4              LP    clus1      1wt       sOFFα        1\n",
       "4        6              LP    clus7      5to         NaN        7\n",
       "5        7              LP   clus10      6sn         NaN       10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(PATH + \"rgc_labels.csv\", index_col=0)\n",
    "\n",
    "cluster_label, cluster_counts = np.unique(labels['cluster'], return_counts=True)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Plotting individual morphologies\n",
    "\n",
    "Load data using `file_manager` and plot individual morphologie using `show_threeview` of from `MorphoPy`. It plots all three planar views on the reconstruction. \n",
    "\n",
    "Here, XY shows the planar view on top of the retina, and Z denotes the location within the inner plexiform layer (IPL).\n",
    "\n",
    "Noted, by default, the `file_manager` loads data with `pca_rot=True` and `soma_center=True`. For the all the exercise in this Coding Lab, it's better to set both of them as `False`. \n",
    "\n",
    "*Grading: 2pts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>type</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>radius</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>3</td>\n",
       "      <td>173.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>3</td>\n",
       "      <td>189.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>293.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>3</td>\n",
       "      <td>314.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "      <td>343.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n  type      x      y     z  radius  parent\n",
       "0      1     1    0.0    0.0  72.0     1.0      -1\n",
       "1      2     3  -14.0  -14.0  50.0     1.0       1\n",
       "2      3     3    5.0   -7.0  66.0     1.0       1\n",
       "3      4     3   18.0  -21.0  49.0     1.0       3\n",
       "4      5     3   10.0    6.0  78.0     1.0       1\n",
       "..   ...   ...    ...    ...   ...     ...     ...\n",
       "197  198     3  173.0   76.0  68.0     1.0     191\n",
       "198  199     3  189.0   95.0  55.0     1.0     198\n",
       "199  200     3  293.0  102.0  76.0     1.0     193\n",
       "200  201     3  314.0  106.0  84.0     1.0     200\n",
       "201  202     3  343.0  103.0  81.0     1.0     201\n",
       "\n",
       "[202 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swc = load_swc(data_path+files[2])\n",
    "swc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nt.NeuronTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      2\n",
      "2      3\n",
      "3      4\n",
      "4      5\n",
      "      ..\n",
      "78    79\n",
      "79    80\n",
      "80    81\n",
      "81    82\n",
      "82    83\n",
      "Name: n, Length: 83, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2.6.3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2872/2711489261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mswc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"n\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# ix = 19\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNeuronTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mswc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\morphopy\\neurontree\\NeuronTree.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, swc, scaling, node_data, edge_data, graph)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \"\"\"\n\u001b[0;32m     67\u001b[0m         \u001b[1;31m# set version of networkX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nxversion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;31m# initialize tree DIRECTED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2.6.3'"
     ]
    }
   ],
   "source": [
    "# get the list of file names\n",
    "from morphopy.computation.file_manager import load_swc_file\n",
    "files = list(os.walk(data_path))[0][2] \n",
    "files.sort()\n",
    "\n",
    "neurons = []\n",
    "\n",
    "for f in files[1:2]:\n",
    "#     print(data_path+f)\n",
    "    swc = load_swc(data_path+f)\n",
    "#     N = nt.NeuronTree(swc=swc)\n",
    "#     neurons.append(N)\n",
    "\n",
    "# ix = 19\n",
    "N = nt.NeuronTree(swc=swc)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "# insert your code here\n",
    "\n",
    "# --------------------------------------------\n",
    "# load example data (ix=19) with `file_manager` \n",
    "# from morphology (1 pt)\n",
    "# --------------------------------------------\n",
    "#N = neurons[ix]\n",
    "\n",
    "# ------------------------------------\n",
    "# plot all three planar views (0.5pts)\n",
    "# ------------------------------------\n",
    "show_threeview(N, fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/nda_ex_10_data/neurons/soma-centered/0002_00535_4L_C01_01.swc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2872/856318420.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mswc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_swc_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\morphopy\\computation\\file_manager.py\u001b[0m in \u001b[0;36mload_swc_file\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \"\"\"\n\u001b[0;32m     16\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     swc = pd.read_csv(filename, delim_whitespace=True, comment='#', converters={'x': f, 'y': f, 'z': f, 'radius': f},\n\u001b[0m\u001b[0;32m     18\u001b[0m                       names=['n', 'type', 'x', 'y', 'z', 'radius', 'parent'], index_col=False)\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/nda_ex_10_data/neurons/soma-centered/0002_00535_4L_C01_01.swc'"
     ]
    }
   ],
   "source": [
    "swc = load_swc_file(data_path+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SWC files are a compact way for storing neural morphologies but their graph structure makes them difficult to handle for current machine learning methods. We, therefore, need to convert our reconstructions into a reasonable vector-like representations. \n",
    "\n",
    "Here we will present two commonly chosen representations: Morphometric statistics and density maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2872/2520078779.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mneurons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mneurons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of reconstructions: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2872/2520078779.py\u001b[0m in \u001b[0;36mload_files\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      4\u001b[0m     The reconstructions are sorted ascendingly by their filename.\"\"\"\n\u001b[0;32m      5\u001b[0m     \u001b[0mneurons\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mfiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# load all reconstructions. Note: files are sorted by cell number\n",
    "def load_files(path):\n",
    "    \"\"\" Returns an object array of NeuronTrees containing all reconstructions at `path`. \n",
    "    The reconstructions are sorted ascendingly by their filename.\"\"\"\n",
    "    neurons = []\n",
    "    path, _, files = list(os.walk(path))[0]\n",
    "    files.sort()\n",
    "\n",
    "    for f in files:\n",
    "\n",
    "        # insert your code here\n",
    "        \n",
    "        # --------------------------------------------\n",
    "        # load data with `file_manager` from morphology\n",
    "        # for all data (0.5 pts)\n",
    "        # --------------------------------------------    \n",
    "       \n",
    "        swc = load_swc(filepath)\n",
    "        N = nt.NeuronTree(swc=swc)\n",
    "        neurons.append(N)\n",
    "    return neurons\n",
    "\n",
    "neurons = load_files(data_path)\n",
    "print(\"Number of reconstructions: \", len(neurons))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Morphometric statistics\n",
    "\n",
    "Morphometric statistics denote a set of hand-crafted single valued features such as `soma radius`, `number of tips` or `average branch angle`. For a more detailed explanation of morphometrics please refer to the [MorphoPy documentation](https://github.com/berenslab/MorphoPy#morphometric-statistics).\n",
    "\n",
    "*Grading: 3pts*\n",
    "\n",
    "First, you should compute this representation for each cell using the function `compute_morphometric_statistics` of the MorphoPy package which computes a predefined set of $28$ statistics. (1pt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from morphopy.computation.feature_presentation import compute_morphometric_statistics\n",
    "\n",
    "# insert your code here\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1. extraction of morphometric statistics on entire data set (0.5 pts)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "ms_list =\n",
    "\n",
    "# -----------------------------------------------------------------------------------\n",
    "# 2. concatenate data into one pd.DataFrame and set the `Cell_nr`` as index (0.5 pts)\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "morphometric_statistics = \n",
    "morphometric_statistics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now visualize the data: Make a scatter plot for each morphometric statistics for each cluster. (1pt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize. Which are the most discriminative ones?\n",
    "\n",
    "features = morphometric_statistics.columns.values\n",
    "\n",
    "fig, axes = plt.subplots(4,7, figsize=(25,10), sharex = True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for k, feature in enumerate(features):\n",
    "    \n",
    "    for l in np.unique(labels['cluster']):\n",
    "       \n",
    "        label_index = (labels['cluster'] == l).values\n",
    "\n",
    "        # insert your code here\n",
    "\n",
    "        # ----------------------\n",
    "        # finish the plot (1 pt)\n",
    "        # ----------------------\n",
    "    \n",
    "    axes[k].set_title(feature.replace(\"_\", \" \"))\n",
    "axes[-1].set_xticks(range(1,15))\n",
    "axes[-1].set_xlabel('Cluster id')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.a:** Which statistics separate clusters well? Which can be removed? (tips: there are 5 uninformative features)  <mark>(1pt)</mark> \n",
    "\n",
    "**Answer:** \n",
    "\n",
    "**Q3.b:** More generally, what do morphometric statistics capture well? What are their advantages, what might be their downsides? Briefly explain. (bonus: 0.5pt)\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For further analysis we will remove uninformative features and z-score along each statistic\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Complete the list with the uninformative features from Q3.a\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "features_to_drop = []\n",
    "\n",
    "morphometric_data = morphometric_statistics.drop(features_to_drop, axis=1)\n",
    "\n",
    "# z-score morphometrics and remove nans and uninformative features\n",
    "morphometric_data = (morphometric_data - morphometric_data.mean())/morphometric_data.std()\n",
    "morphometric_data[morphometric_data.isna()] = 0\n",
    "morphometric_data = morphometric_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Density maps\n",
    "\n",
    "Density maps project a neuron's 3D point cloud ($x$, $y$, $z$) onto a plane or an axis, and bin the projected point cloud into a fixed number of bins. Hereby, the binning controls how much global or local information is kept, which majorly affects the results.\n",
    "While density maps ignore the connectivity between nodes and only assign value to neurite density, this representation can be powerful, when cell type and location in the brain area are highly correlated. \n",
    "\n",
    "**Exercise:** Compute the density maps of all neurons onto all cardinal planes and axes using the method `compute_density_maps`. You can manipulate the parameters for the density maps via the dictonary `config`. \n",
    "Make sure that you normalize the density maps globally and bin each direction into $20$ bins.\n",
    "You are welcome to explore, how the different projections look like but we will only use the z-projection for further analysis.\n",
    "\n",
    "\n",
    "Possible parameters to pass are:\n",
    "\n",
    "- distance: (default=1, in microns) determines the resampling distance.\n",
    "- bin_size: (default=20, in microns). If set the number of bins will be computed such that one bin \n",
    "spans `bin_size` microns. This is overwritten when `n_bins_x/y/z` is set!\n",
    "- n_bins_x/y/z: (default=None) specifies the number of bins for each dimension. If set it will overwrite the \n",
    "`bin_size` flag.\n",
    "- density: (default=True) bool to specify if a density or counts are returned.\n",
    "- smooth: (default=True) bool to trigger Gaussian smoothing.\n",
    "- sigma: (default=1) determines std of the Gaussian used for smoothing. The bigger the sigma the more smoothing occurs. If smooth is set to False this parameter is ignored. \n",
    "- r_min_x/y/z: (in microns) minimum range for binning of x, y, and z. This value will correspond to the \n",
    "minimal histogram edge. \n",
    "- r_max_x/y/z: (in microns) maximum range for binning for x, y, and z. This value will correspond to the \n",
    "maximal histogram edge. \n",
    "\n",
    "*Grading: 3pts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "# Find the minimal and maximal x, y,z - coordinates in the data set to normalize \n",
    "# the density maps globally which corresponds to r_min_x/y/z and r_max_x/y/z (1 pt)\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "minimal_coordinates = \n",
    "maximal_coordinates =\n",
    "\n",
    "print('Minimal coordinates: ', minimal_coordinates)\n",
    "print('Maximal coordinates: ', maximal_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from morphopy.computation.feature_presentation import compute_density_maps\n",
    "\n",
    "# ------------------------------\n",
    "# complete the config dict (1pt)\n",
    "# ------------------------------\n",
    "\n",
    "config_global = dict(distance=,\n",
    "                     n_bins_x=,\n",
    "                     n_bins_y=, \n",
    "                     n_bins_z=, \n",
    "               density=True,smooth=True, sigma=1, \n",
    "               r_max_x=maximal_coordinates[0], r_max_y=maximal_coordinates[1], r_max_z=maximal_coordinates[2], \n",
    "               r_min_x=minimal_coordinates[0], r_min_y=minimal_coordinates[1], r_min_z=minimal_coordinates[2])\n",
    "\n",
    "density_maps= [compute_density_maps(n, config_params=config_global) for n in neurons] # this line might take a while\n",
    "\n",
    "# extract the z density map\n",
    "DM_Z = np.array([dm['z_proj']['data'] for dm in density_maps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot z-density maps of 5 randomly chosen individual cells\n",
    "random_index = np.random.choice(range(len(neurons)), size=5, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(1,5,figsize=(12,3), sharey=True)\n",
    "for k, ix in enumerate(random_index):\n",
    "    axes[k].plot(DM_Z[ix,:],range(20), c='lightgrey')\n",
    "    axes[k].set_title('Cluster %i'%labels.iloc[ix]['cluster'])\n",
    "sns.despine()\n",
    "axes[0].set_ylabel('Bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 14, figsize=(21,3), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# insert your code here\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# plot the Z-density map sorted by class label (1 pt)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "sns.despine()\n",
    "axes[0].set_yticks([0,5,10,15,19])\n",
    "axes[0].set_yticklabels(density_maps[0]['z_proj']['edges'][0][[0,5,10,15,19]].astype(int))\n",
    "_ = axes[0].set_ylabel('Z [microns]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D embedding using t-SNE\n",
    "\n",
    "\n",
    "Embed both data, the morphometric statistics and the density maps, in 2D using t-SNE and color each embedded point by its cluster assignment.\n",
    "\n",
    "We use `openTSNE` for this part: `pip install opentsne`\n",
    "\n",
    "*Grading: 2pts*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE import TSNE\n",
    "\n",
    "# insert your code here\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Fit t-SNE with morphometric statistics and density maps (0.5 + 0.5 pt)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "tsne = TSNE(\n",
    "    perplexity=100,\n",
    "    initialization='pca',\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=20,\n",
    "    random_state=17,\n",
    ")\n",
    "\n",
    "tsne_fit_morph = tsne.fit(morphometric_data)\n",
    "tsne_fit_dm = tsne.fit(DM_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "# insert your code here\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# plot tsne fit of morpometric statistics, color-coded with cluster labels (0.5 pts)\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "axes[0].set_xlabel('t-SNE 1 [a.u.]')\n",
    "axes[0].set_ylabel('t-SNE 2 [a.u.]')\n",
    "\n",
    "axes[0].set_title('Morphometric statistics')\n",
    "\n",
    "# ------------------------------------------------------------------------------------\n",
    "# plot tsne fit of z-projected density map , color-coded with cluster labels (0.5 pts)\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "axes[1].set_xlabel('t-SNE 1 [a.u.]')\n",
    "axes[1].set_ylabel('t-SNE 2 [a.u.]')\n",
    "plt.legend(frameon=False, bbox_to_anchor=(1,1.1))\n",
    "axes[1].set_title('Z density maps')\n",
    "\n",
    "plt.suptitle('t-SNE embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we do not have access to ground truth cell type labels but we need to infer the number of classes that are present in the data. In the following we want to explore hierarchical clustering based on morphometric statistics and on density maps. Assume that you know the number of existing cluster ($N_{clus}=14$). Visualize the clustering dendrogram (use seaborn's `clustermap` method) and then cluster the data (using agglomerative clustering and Ward's method) and assess the cluster label correspondence with ground truth labels using [two custer quality metrics](https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation) of your choice.\n",
    "\n",
    "*Bonus: 2.5 pts*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering on morphometric statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = labels['cluster'].values\n",
    "sns.clustermap(morphometric_data, method='ward',\n",
    "               row_colors=[colors[t-1] for t in true_labels],\n",
    "               cbar_pos=(1., 0.6, 0.05, 0.18), \n",
    "               xticklabels = [f.replace(\"_\", \" \").capitalize() for f in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import mutual_info_score, adjusted_rand_score\n",
    "\n",
    "# insert your code here\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Do hierarchical clustering with morphometric statistics (1 pt)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "agglom_morph = \n",
    "\n",
    "print('Mutual information score:',  mutual_info_score(labels['cluster'].values, agglom_morph.labels_))\n",
    "print('Adjusted rand index: ', adjusted_rand_score(labels['cluster'].values, agglom_morph.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering on density maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(DM_Z, method='ward', \n",
    "               row_cluster=True, \n",
    "               row_colors=[colors[t-1] for t in true_labels], \n",
    "               cbar_pos=(1., 0.6, 0.05, 0.18), \n",
    "               xticklabels=['Bin %i'%i for i in range(1,21)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Do hierarchical clustering with density map (1 pt)\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "agglom_dm = \n",
    "\n",
    "print('Mutual information score:',  mutual_info_score(labels['cluster'].values, agglom_dm.labels_))\n",
    "print('Adjusted rand index: ', adjusted_rand_score(labels['cluster'].values, agglom_dm.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the t-SNE embeddings from before and label each embedding with its true and, next to it, with its newly inferred cluster labels from the agglomerative clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot t-sne with cluster labels of both representations\n",
    "\n",
    "new_cluster_colors = sns.color_palette('tab20', n_colors=14)\n",
    "\n",
    "### density maps ######\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "axes = axes.flatten()\n",
    "# plot the true cluster labels \n",
    "for k, l in enumerate(np.unique(labels['cluster'])):\n",
    "    label_index = (labels['cluster'] == l).values\n",
    "    axes[0].scatter(tsne_fit_dm[label_index,0], tsne_fit_dm[label_index,1], c=[colors[k]], label='Cluster %i'%l)\n",
    "\n",
    "axes[0].set_xlabel('t-SNE 1 [a.u.]')\n",
    "axes[0].set_ylabel('t-SNE 2 [a.u.]')\n",
    "axes[0].set_title('True cluster')\n",
    "\n",
    "# plot the new clustering\n",
    "for k,l in enumerate(np.unique(agglom_dm.labels_)):\n",
    "    label_index = agglom_dm.labels_ == l\n",
    "    axes[1].scatter(tsne_fit_dm[label_index,0], tsne_fit_dm[label_index,1], c=[new_cluster_colors[k]])\n",
    "axes[1].set_xlabel('t-SNE 1 [a.u.]')\n",
    "axes[1].set_ylabel('t-SNE 2 [a.u.]')\n",
    "axes[1].set_title('Inferred cluster')\n",
    "sns.despine()\n",
    "plt.suptitle('Z-density map')\n",
    "\n",
    "### morphometrics ######\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# plot the true cluster labels \n",
    "for k, l in enumerate(np.unique(labels['cluster'])):\n",
    "    label_index = (labels['cluster'] == l).values\n",
    "    axes[0].scatter(tsne_fit_morph[label_index,0], tsne_fit_morph[label_index,1], c=[colors[k]], label='Cluster %i'%l)\n",
    "\n",
    "axes[0].set_xlabel('t-SNE 1 [a.u.]')\n",
    "axes[0].set_ylabel('t-SNE 2 [a.u.]')\n",
    "axes[0].set_title('True cluster')\n",
    "\n",
    "# plot the new clustering\n",
    "for k,l in enumerate(np.unique(agglom_morph.labels_)):\n",
    "    label_index = agglom_morph.labels_ == l\n",
    "    axes[1].scatter(tsne_fit_morph[label_index,0], tsne_fit_morph[label_index,1], c=[new_cluster_colors[k]])\n",
    "\n",
    "axes[1].set_xlabel('t-SNE 1 [a.u.]')\n",
    "axes[1].set_ylabel('t-SNE 2 [a.u.]')\n",
    "axes[1].set_title('Inferred cluster')\n",
    "sns.despine()\n",
    "plt.suptitle('Morphometric statistics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Which representation allows for better recovery of the cell type labels? Why is that so? (0.5pt)\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Predicting the projection site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of its cell type, we now want to predict each cell's projection site in the thalamus which is stored in the column `labels['projection_site']`. Fit a logistic regression on both morphological representations and report its average cross validated (cv=5) prediction accuracy for each. Which representation works better to recover the prediction target? Which features are most relevant for that prediction?\n",
    "\n",
    "\n",
    "You can use `LogisticRegressionCV` of the scikit-learn library directly. Since the classes are imbalanced make sure to report the balanced prediction accuracy. To understand the relevance of individual features plot the fitted linear coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "# Fit logistic regression on density maps\n",
    "lr_dm = LogisticRegressionCV(scoring='balanced_accuracy')\n",
    "lr_dm.fit(DM_Z, labels['projection_site'].values)\n",
    "print('Average projection site prediction accuracy on density maps: %i percent'%(lr_dm.score(DM_Z, labels['projection_site'].values)*100))\n",
    "\n",
    "\n",
    "# Fit logistic regression on morphometric data\n",
    "lr_morph = LogisticRegressionCV(scoring='balanced_accuracy')\n",
    "lr_morph.fit(morphometric_data, labels['projection_site'].values)\n",
    "print('Average projection site prediction accuracy on morphometric data: %i percent'%(lr_morph.score(morphometric_data, labels['projection_site'].values)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Z density maps allow for better recovery of cell type labels, they are worse than morphometric statistics on predicting the projection target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lr_morph\n",
    "\n",
    "plt.plot(lr.coef_.T)\n",
    "plt.gca().set_xticks(range(28))\n",
    "_ = plt.gca().set_xticklabels([f.replace(\"_\", \" \").capitalize() for f in features], rotation=90)\n",
    "plt.plot(range(lr.n_features_in_), [0]*lr.n_features_in_, c='grey', ls='--')\n",
    "sns.despine()\n",
    "plt.ylabel('Coefficient value')\n",
    "plt.title('Linear weights vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Which morphometrics are informative on the projection site?\n",
    "\n",
    "**Answer:** All that are related to size. The cells projecting to Pbg tend to be bigger in dendritic diameter ($width \\times depth$) and have wider branch angles. This is also in line with what Reinhard et al. find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further references\n",
    "\n",
    "Other ways to represent and compare morphologies are\n",
    "* Persistence: [Description](https://link.springer.com/article/10.1007/s12021-017-9341-1) and [application on somatosensory pyramidal cell dendrites](https://academic.oup.com/cercor/article/29/4/1719/5304727) by Kanari et al. 2018\n",
    "\n",
    "* Tree edit distance: [Heumann et al. 2009](https://link.springer.com/article/10.1007/s12021-009-9051-4)\n",
    "\n",
    "* Sequential encoding inspired by BLAST: [Encoding](https://link.springer.com/article/10.1186/s12859-015-0604-2) and [similarity analysis on cortical dendrites](https://link.springer.com/article/10.1186/s12859-015-0605-1) by Gilette et al. 2015\n",
    "\n",
    "* Vector point clouds: [BlastNeuron: Wan et al. 2015](https://link.springer.com/article/10.1007/s12021-015-9272-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a52f57b56c27f38fc3d95daa57af6da3929fe8541a384ec0d11efb6a1b206eb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
